{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a0b2873-029b-4ad3-bb7b-67b210d0fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "009cf272-4f48-4a50-a42b-d36e39d39cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b02b0d7-8f26-42ee-97cf-d373066ba9d1",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44d250d0-f4a1-43df-b5d7-2db24dab4dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current directory: /home/jloesch30/school/DeepLearningFinalProject/data engineering\n"
     ]
    }
   ],
   "source": [
    "curr_dir = os.getcwd()\n",
    "print(f\"Your current directory: {curr_dir}\")\n",
    "\n",
    "path = \"../data/\"\n",
    "files = [file for file in listdir(path) if isfile(join(path, file))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f6119df-18d7-45cf-9e62-4e87a8b6427a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UkraineCombinedTweetsDeduped_MAR01.csv.gzip\n",
      "UkraineCombinedTweetsDeduped20220227-131611.csv.gzip\n",
      "UkraineCombinedTweetsDeduped_MAR04.csv.gzip\n",
      "UkraineCombinedTweetsDeduped_MAR07.csv.gzip\n",
      "UkraineCombinedTweetsDeduped_MAR05.csv.gzip\n",
      "UkraineCombinedTweetsDeduped_MAR03.csv.gzip\n",
      "UkraineCombinedTweetsDeduped_FEB28_part1.csv.gzip\n",
      "UkraineCombinedTweetsDeduped_FEB28_part2.csv.gzip\n",
      "UkraineCombinedTweetsDeduped_MAR06.csv.gzip\n",
      "UkraineCombinedTweetsDeduped_FEB27.csv.gzip\n",
      "UkraineCombinedTweetsDeduped_MAR02.csv.gzip\n"
     ]
    }
   ],
   "source": [
    "# all files in the data folder\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fb90fa0-6efe-443d-ab03-6523eb9165b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract csv files\n",
    "\"\"\"\n",
    "\n",
    "import gzip\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "name_pattern = r\"^[A-Za-z0-9\\_\\-]+\"\n",
    "\n",
    "path = \"../data/\"\n",
    "\n",
    "for file in files:\n",
    "   with gzip.open(path + file, \"rt\") as f_in:\n",
    "    match = re.findall(name_pattern, file)[0]\n",
    "    data = f_in.read()\n",
    "    with open(path + \"csv/\" + match + \".csv\", \"wt+\") as f_out:\n",
    "        f_out.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c69af77-4d06-4ccd-9fae-7e9ce3e4789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "filename27_1 = r\"../data/csv/UkraineCombinedTweetsDeduped_FEB27.csv\"\n",
    "filename28_1 = r\"../data/csv/UkraineCombinedTweetsDeduped_FEB28_part1.csv\"\n",
    "filename27_2 = r\"../data/csv/UkraineCombinedTweetsDeduped20220227-131611.csv\"\n",
    "filename28_2 = r\"../data/csv/UkraineCombinedTweetsDeduped_FEB28_part2.csv\"\n",
    "filename01  = r\"../data/csv/UkraineCombinedTweetsDeduped_MAR01.csv\"\n",
    "filename02  = r\"../data/csv/UkraineCombinedTweetsDeduped_MAR02.csv\"\n",
    "\n",
    "df27_1 = pd.read_csv(filename27_1, index_col=0,encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "df28_1 = pd.read_csv(filename28_1,  index_col=0,encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "df27_2 = pd.read_csv(filename27_2,  index_col=0,encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "df28_2 = pd.read_csv(filename28_2,  index_col=0,encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "df_0301 = pd.read_csv(filename01,  index_col=0,encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "df_0302 = pd.read_csv(filename02,  index_col=0,encoding='utf-8', quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "075da18d-553e-44cd-8391-45e6218ce3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1586367 tweets from 27th FEB\n",
      "378171 tweets from 28th FEB\n",
      "409279 tweets from 1st march\n",
      "2790848 tweets from the last 3 days\n"
     ]
    }
   ],
   "source": [
    "df27 = pd.concat([df27_1,df27_2])\n",
    "df28 = pd.concat([df28_1,df28_2])\n",
    "df = pd.concat([df27,df28,df_0301,df_0302])\n",
    "\n",
    "print(len(df27), 'tweets from 27th FEB')\n",
    "print(len(df28), 'tweets from 28th FEB')\n",
    "print(len(df_0301),'tweets from 1st march')\n",
    "print(len(df),'tweets from the last 3 days')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ad4ed2-d593-4708-b713-93c436ee2d07",
   "metadata": {},
   "source": [
    "## Labeling and Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87fe7651-c63b-4be2-b4af-599f4abb603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ru = df[df[\"language\"] == \"ru\"]\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    #Make text lowercase   \n",
    "    text = text.lower()\n",
    "    # remove new line characters\n",
    "    text = text.replace('\\n', \" \")\n",
    "    #remove text in square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    #remove punctuation   \n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text) \n",
    "    #remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    #remove links   \n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    #remove emojis    \n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    text = regrex_pattern.sub(r'', text)\n",
    "    return text\n",
    "\n",
    "df_cleaned = pd.DataFrame(df_ru.text.apply(lambda x: clean_text(x)))\n",
    "\n",
    "# store all values of df_cleaned in a list\n",
    "lst_cleaned = df_cleaned['text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a010f9b-d25b-4080-979f-9834e4b0098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Instead of iterating through and generating new calls, I believe doing it this way batches the requests and uses one access token\n",
    "\"\"\"\n",
    "\n",
    "# send list values into the translator\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "translations = translator.translate(lst_cleaned, dest='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9cd5e299-8bfd-4450-b492-e980310a26ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: russian invasion on ukraine  ukraineinvasion харьков район даниловка кадры пожара после взрыва нефтебазы \n",
      "Translated: russian invasion in ukraine ukraine invasion kharkov danilovka district footage of the fire after the explosion\n",
      "--------------------\n",
      "original: русский сдавайся в плен  нет смысла умереть за палацы и яхты путина  тебя не убьют и будут хорошо кормить  даже разрешат мамке позвонить  ukrainewar ukrainerussia news putin swift россия москва война украина україна india france london uk usa japan brazil \n",
      "Translated: russian surrender it makes no sense to die for Putin's palaces and yachts they won't kill you and they will feed you well even let your mother call ukrainewar ukrainerussia news putin swift russia moscow war ukraine india france london uk usa japan brazil\n",
      "--------------------\n",
      "original: morgenshterh дай пинка durov чё он не банит в телеге каналы призывающие ставить метки для ударов и остальных прокремлевских шлюх  stoprussia ukraine helpukraine\n",
      "Translated: morgenshterh give me a kick durov why doesn't he ban in the cart channels calling to put marks for blows and other pro-Kremlin whores stoprussia ukraine helpukraine\n",
      "--------------------\n",
      "original: microdistrict danilovka видео взрыва микрорайон даниловка ukrainerussiawar ukrainerussia stoprussianaggression standwithukraine poutine prayforukraine ukraine ukrainewar ukrania \n",
      "Translated: microdistrict danilovka explosion video danilovka microdistrict ukrainerussiawar ukrainerussia stoprussianaggression standwithukraine poutine prayforukraine ukraine ukrainewar ukrania\n",
      "--------------------\n",
      "original: kyiv україна  ukraine   эвакуировать население из василькова не планируют  «угрозы людям нет» — спикер гсчс киевской области виктория рубан \n",
      "Translated: kyiv ukraine ukraine do not plan to evacuate the population from vasylkiv \"there is no threat to people\" - speaker of the state emergency service of the kiev region victoria ruban\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, text in enumerate(translations):\n",
    "    if idx == 5:\n",
    "        break\n",
    "    print(f\"original: {text.origin}\\nTranslated: {text.text}\\n{'-'*20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "744683f8-b980-40c1-9f00-9de597ae2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_translations = []\n",
    "for translation in translations:\n",
    "    lst_translations.append(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a9836e82-149d-46b2-86d7-53155eeb2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace df_clean_ru text column with new translations\n",
    "\n",
    "df_cleaned['text'] = lst_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42c26e4d-fbb9-490f-83bf-d313ca054605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1143139    russian invasion in ukraine ukraine invasion k...\n",
       "1143146    russian surrender it makes no sense to die for...\n",
       "1143405    morgenshterh give me a kick durov why doesn't ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['text'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "379bb08e-c14b-45cc-b225-1243f4ddc204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframe of translated russian text\n",
    "df_cleaned.to_csv(\"./translated_russian.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47902c99-d7f2-4246-86a0-933f50f4276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text    guys i really need help please maximum repost ...\n",
      "Name: 1312641, dtype: object\n",
      "\n",
      "text    guys i really need help please maximum repost ...\n",
      "Name: 1312727, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This message appears a lot of times in the dataset FYI\n",
    "\"\"\"\n",
    "\n",
    "print(df_cleaned.iloc[583])\n",
    "print()\n",
    "print(df_cleaned.iloc[585])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed4002da-e2b7-443a-a7c2-417b690cb6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated_string = df_cleaned[df_cleaned['text'] == df_cleaned.iloc[583].text]\n",
    "len(repeated_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
